{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DetectWheats.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"IGYJNJeOZJk_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"7b02fc12-3423-4b5f-8423-032c764212d5","executionInfo":{"status":"ok","timestamp":1538661343973,"user_tz":-180,"elapsed":3834,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["!uptime"],"execution_count":1,"outputs":[{"output_type":"stream","text":[" 13:55:41 up 34 min,  0 users,  load average: 1.28, 1.41, 1.41\n"],"name":"stdout"}]},{"metadata":{"id":"dQbb-Jkt4Gcs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":161},"outputId":"1d2fad55-84a0-45b4-9668-79458388cdb1","executionInfo":{"status":"ok","timestamp":1538661524355,"user_tz":-180,"elapsed":180356,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["!git clone https://github.com/dozzer/DetectWheats.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'DetectWheats'...\n","remote: Enumerating objects: 2748, done.\u001b[K\n","remote: Counting objects: 100% (2748/2748), done.\u001b[K\n","remote: Compressing objects: 100% (1694/1694), done.\u001b[K\n","remote: Total 2748 (delta 1067), reused 2728 (delta 1047), pack-reused 0\u001b[K\n","Receiving objects: 100% (2748/2748), 228.19 MiB | 1.34 MiB/s, done.\n","Resolving deltas: 100% (1067/1067), done.\n","Checking out files: 100% (2951/2951), done.\n"],"name":"stdout"}]},{"metadata":{"id":"VD2Kfil_nzTd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"31a148f8-6123-4639-a2b7-7e419ce04ca4","executionInfo":{"status":"ok","timestamp":1538661528265,"user_tz":-180,"elapsed":3874,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["!cd DetectWheats && git pull"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Already up to date.\n"],"name":"stdout"}]},{"metadata":{"id":"Bjwry2q484dl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1225},"outputId":"0956cc19-9910-4249-e685-fc0afa579a0a","executionInfo":{"status":"ok","timestamp":1538661538743,"user_tz":-180,"elapsed":10455,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["!pip install -r DetectWheats/requirements.txt"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from -r DetectWheats/requirements.txt (line 1)) (4.0.0)\n","Collecting lxml (from -r DetectWheats/requirements.txt (line 2))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a4/9eea8035fc7c7670e5eab97f34ff2ef0ddd78a491bf96df5accedb0e63f5/lxml-4.2.5-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n","\u001b[K    100% |████████████████████████████████| 5.8MB 864kB/s \n","\u001b[?25hCollecting jupyter (from -r DetectWheats/requirements.txt (line 3))\n","  Downloading https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r DetectWheats/requirements.txt (line 4)) (2.1.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r DetectWheats/requirements.txt (line 5)) (3.4.3.18)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->-r DetectWheats/requirements.txt (line 1)) (0.46)\n","Collecting ipywidgets (from jupyter->-r DetectWheats/requirements.txt (line 3))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/9a/a008c7b1183fac9e52066d80a379b3c64eab535bd9d86cdc29a0b766fd82/ipywidgets-7.4.2-py2.py3-none-any.whl (111kB)\n","\u001b[K    100% |████████████████████████████████| 112kB 29.3MB/s \n","\u001b[?25hRequirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->-r DetectWheats/requirements.txt (line 3)) (5.4.0)\n","Collecting qtconsole (from jupyter->-r DetectWheats/requirements.txt (line 3))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1f/b340d52dee46fbbe8a097dce76d1197258bb599692159d94c80921fef9eb/qtconsole-4.4.1-py2.py3-none-any.whl (112kB)\n","\u001b[K    100% |████████████████████████████████| 112kB 29.1MB/s \n","\u001b[?25hCollecting jupyter-console (from jupyter->-r DetectWheats/requirements.txt (line 3))\n","  Downloading https://files.pythonhosted.org/packages/cb/ee/6374ae8c21b7d0847f9c3722dcdfac986b8e54fa9ad9ea66e1eb6320d2b8/jupyter_console-6.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->-r DetectWheats/requirements.txt (line 3)) (5.2.2)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->-r DetectWheats/requirements.txt (line 3)) (4.6.1)\n","Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r DetectWheats/requirements.txt (line 4)) (1.14.6)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r DetectWheats/requirements.txt (line 4)) (1.11.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r DetectWheats/requirements.txt (line 4)) (2018.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r DetectWheats/requirements.txt (line 4)) (2.2.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r DetectWheats/requirements.txt (line 4)) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r DetectWheats/requirements.txt (line 4)) (2.5.3)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3)) (4.3.2)\n","Collecting widgetsnbextension~=3.4.0 (from ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/81/35789a3952afb48238289171728072d26d6e76649ddc8b3588657a2d78c1/widgetsnbextension-3.4.2-py2.py3-none-any.whl (2.2MB)\n","\u001b[K    100% |████████████████████████████████| 2.2MB 12.4MB/s \n","\u001b[?25hRequirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3)) (5.5.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3)) (4.4.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (1.4.2)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.4.2)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.2.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (2.1.4)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (2.1.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.5.0)\n","Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.8.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (4.4.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->-r DetectWheats/requirements.txt (line 3)) (5.2.3)\n","Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->-r DetectWheats/requirements.txt (line 3))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c5/f1ee6698bdcf615f171a77e81ca70293b16a6d82285f1760b388b4348263/prompt_toolkit-2.0.5-py3-none-any.whl (334kB)\n","\u001b[K    100% |████████████████████████████████| 337kB 20.8MB/s \n","\u001b[?25hRequirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->-r DetectWheats/requirements.txt (line 3)) (4.5.3)\n","Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3)) (4.3.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3)) (39.1.0)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3)) (4.6.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.8.1)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->-r DetectWheats/requirements.txt (line 3)) (2.6.0)\n","Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (1.0.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (1.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->-r DetectWheats/requirements.txt (line 3)) (16.0.4)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.1.7)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.6.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->jupyter->-r DetectWheats/requirements.txt (line 3)) (0.5.1)\n","\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.5 which is incompatible.\u001b[0m\n","Installing collected packages: lxml, widgetsnbextension, ipywidgets, qtconsole, prompt-toolkit, jupyter-console, jupyter\n","  Found existing installation: prompt-toolkit 1.0.15\n","    Uninstalling prompt-toolkit-1.0.15:\n","      Successfully uninstalled prompt-toolkit-1.0.15\n","Successfully installed ipywidgets-7.4.2 jupyter-1.0.0 jupyter-console-6.0.0 lxml-4.2.5 prompt-toolkit-2.0.5 qtconsole-4.4.1 widgetsnbextension-3.4.2\n"],"name":"stdout"}]},{"metadata":{"id":"XwIjYErZAJDc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"e471c75e-d676-4d70-b9fb-514eeaa5cfe2","executionInfo":{"status":"ok","timestamp":1538661556111,"user_tz":-180,"elapsed":17323,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["!pip install Cython\n","!pip install pycocotools"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting Cython\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/8e/32b280abb0947a96cdbb8329fb2014851a21fc1d099009f946ea8a8202c3/Cython-0.28.5-cp36-cp36m-manylinux1_x86_64.whl (3.4MB)\n","\u001b[K    100% |████████████████████████████████| 3.4MB 952kB/s \n","\u001b[?25hInstalling collected packages: Cython\n","Successfully installed Cython-0.28.5\n","Collecting pycocotools\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/84/9a07b1095fd8555ba3f3d519517c8743c2554a245f9476e5e39869f948d2/pycocotools-2.0.0.tar.gz (1.5MB)\n","\u001b[K    100% |████████████████████████████████| 1.5MB 11.6MB/s \n","\u001b[?25hBuilding wheels for collected packages: pycocotools\n","  Running setup.py bdist_wheel for pycocotools ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/dc/e6/36/0e1ae88c868eb42d3f92181b1c9bbd0b217a7ec3da6bd62e55\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","Successfully installed pycocotools-2.0.0\n"],"name":"stdout"}]},{"metadata":{"id":"Cq5xDL_NBGi8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"outputId":"547e7771-da04-4a33-ee3f-2b81596c8a88","executionInfo":{"status":"ok","timestamp":1538661560622,"user_tz":-180,"elapsed":4473,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["!pip install -U prompt-toolkit==1.0.15"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting prompt-toolkit==1.0.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/c6616dd03701e7e2073f06d5c3b41b012256e42b72561f16a7bd86dd7b43/prompt_toolkit-1.0.15-py3-none-any.whl (247kB)\n","\u001b[K    100% |████████████████████████████████| 256kB 7.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit==1.0.15) (1.11.0)\n","Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit==1.0.15) (0.1.7)\n","\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n","Installing collected packages: prompt-toolkit\n","  Found existing installation: prompt-toolkit 2.0.5\n","    Uninstalling prompt-toolkit-2.0.5:\n","      Successfully uninstalled prompt-toolkit-2.0.5\n","Successfully installed prompt-toolkit-1.0.15\n"],"name":"stdout"}]},{"metadata":{"id":"SkyLkaYJ9Pno","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":539},"outputId":"a80a2225-ccad-4444-80d9-e39fd25d675a","executionInfo":{"status":"ok","timestamp":1538661573342,"user_tz":-180,"elapsed":11127,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["!apt-get install protobuf-compiler"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libprotobuf10 libprotoc10\n","The following NEW packages will be installed:\n","  libprotobuf10 libprotoc10 protobuf-compiler\n","0 upgraded, 3 newly installed, 0 to remove and 4 not upgraded.\n","Need to get 1,242 kB of archives.\n","After this operation, 4,942 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotobuf10 amd64 3.0.0-9.1ubuntu1 [651 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libprotoc10 amd64 3.0.0-9.1ubuntu1 [566 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 protobuf-compiler amd64 3.0.0-9.1ubuntu1 [24.5 kB]\n","Fetched 1,242 kB in 3s (474 kB/s)\n","Selecting previously unselected package libprotobuf10:amd64.\n","(Reading database ... 21063 files and directories currently installed.)\n","Preparing to unpack .../libprotobuf10_3.0.0-9.1ubuntu1_amd64.deb ...\n","Unpacking libprotobuf10:amd64 (3.0.0-9.1ubuntu1) ...\n","Selecting previously unselected package libprotoc10:amd64.\n","Preparing to unpack .../libprotoc10_3.0.0-9.1ubuntu1_amd64.deb ...\n","Unpacking libprotoc10:amd64 (3.0.0-9.1ubuntu1) ...\n","Selecting previously unselected package protobuf-compiler.\n","Preparing to unpack .../protobuf-compiler_3.0.0-9.1ubuntu1_amd64.deb ...\n","Unpacking protobuf-compiler (3.0.0-9.1ubuntu1) ...\n","Setting up libprotobuf10:amd64 (3.0.0-9.1ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","Setting up libprotoc10:amd64 (3.0.0-9.1ubuntu1) ...\n","Setting up protobuf-compiler (3.0.0-9.1ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"],"name":"stdout"}]},{"metadata":{"id":"3vgicpDo9Tiy","colab_type":"code","colab":{}},"cell_type":"code","source":["!cd DetectWheats && protoc object_detection/protos/*.proto --python_out=."],"execution_count":0,"outputs":[]},{"metadata":{"id":"VJVTo4rP9dFn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1025},"outputId":"19477942-356b-4884-bf77-a9d6587be98b","executionInfo":{"status":"ok","timestamp":1538661582114,"user_tz":-180,"elapsed":5468,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["!cd DetectWheats && python create_tf_record.py \\\n","    --data_dir=`pwd` \\\n","    --output_dir=`pwd`"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:root:Could not find annotations/xmls/_DSC4162_NyPl77qa43.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_lTkmRZqaaj.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_qjwFKD2EIu.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_r1KwsyPaYb.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_wUwTH3rMib.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_DeAMTAZT70.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_0pAcVEkLGq.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_Rojawb1Ck1.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_tLeZyNe7zj.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_ON6GjsFPJK.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4174_OBUEEbpBsV.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_xRUbxTmYOn.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_GNmHTlqQzr.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_upIhOgEHEm.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_G9DP2RA2Zo.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_fSzAwCwUvy.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_ibOUucoXCK.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_WkR4cqKt40.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4174_luLmbcekXg.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_HA3LkJPrfV.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_qbw6cg98Ut.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_ZPCxIRhGOs.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_myAotKtaFT.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_JPrwPQP8t8.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_MzINAfG0lZ.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4174.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_vk6obCYsWr.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4174_nW7MnHMK96.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_UoWV4xUvOf.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_oaR84zdduU.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_ZnOaMqjIrU.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_kd5j0Ujyw1.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_F7xkjWrxjC.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_9YtvCZlo2c.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_CMb0yZUisY.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4174_9ZEENIYJQr.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_ua3awRQXi5.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_p9WWWF2CwK.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_kxiR4kxbFu.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_O6oYrlBq0j.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_T7jJSHFF5E.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_EDvZNizYtD.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_wOEQSwj3dI.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4174_9OgcVGG6A5.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_shpiZ1TjYL.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_VMoKkC08Vu.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4174_ovMpv3Ay5h.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_l3puUbWmhB.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_xBUjxWtWTp.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_tCOxr2tKPH.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_Cg90HhJ9v9.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_p7go7W1fCJ.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4176_1Gs3zfUyFW.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_afJ4VWR1tP.xml.xml, ignoring example.\n","WARNING:root:Could not find annotations/xmls/_DSC4162_r8MFCNCWMp.xml.xml, ignoring example.\n"],"name":"stdout"}]},{"metadata":{"id":"w9BLXdI-9ik9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":215},"outputId":"1a3932f9-057d-44a9-a354-a87d34ed2458","executionInfo":{"status":"ok","timestamp":1538661596902,"user_tz":-180,"elapsed":14761,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["!wget -P DetectWheats http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz \n","!cd DetectWheats && tar -xzf faster_rcnn_resnet50_coco_2018_01_28.tar.gz"],"execution_count":11,"outputs":[{"output_type":"stream","text":["--2018-10-04 13:59:44--  http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.97.128, 2404:6800:4008:c00::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.97.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 381355771 (364M) [application/x-tar]\n","Saving to: ‘DetectWheats/faster_rcnn_resnet50_coco_2018_01_28.tar.gz’\n","\n","faster_rcnn_resnet5 100%[===================>] 363.69M   121MB/s    in 3.0s    \n","\n","2018-10-04 13:59:47 (121 MB/s) - ‘DetectWheats/faster_rcnn_resnet50_coco_2018_01_28.tar.gz’ saved [381355771/381355771]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"fmI90-S--QWo","colab_type":"code","colab":{}},"cell_type":"code","source":["import sys,os,os.path\n","os.environ['PYTHONPATH']=os.path.join(os.getcwd(),\"DetectWheats\")+\":\"+os.path.join(os.getcwd(),\"DetectWheats\",\"slim\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4LOs9QXYZrxC","colab_type":"code","colab":{}},"cell_type":"code","source":["MODEL_DIR = \"faster_rcnn_resnet50_coco_out_17_48\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"y2HbHEIK9zkK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1506},"outputId":"89bd2f4c-86fc-49a2-aa6d-e611b808bc7b"},"cell_type":"code","source":["!cd DetectWheats && python object_detection/model_main.py \\\n","  --pipeline_config_path=faster_rcnn_resnet50_coco.config \\\n","  --model_dir=$MODEL_DIR \\\n","  --num_train_steps=1000 \\\n","  --num_eval_steps=1000 \\\n","  --alsologtostderr"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/DetectWheats/object_detection/utils/visualization_utils.py:27: UserWarning: \n","This call to matplotlib.use() has no effect because the backend has already\n","been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n","or matplotlib.backends is imported for the first time.\n","\n","The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n","  File \"object_detection/model_main.py\", line 26, in <module>\n","    from object_detection import model_lib\n","  File \"/content/DetectWheats/object_detection/model_lib.py\", line 27, in <module>\n","    from object_detection import eval_util\n","  File \"/content/DetectWheats/object_detection/eval_util.py\", line 27, in <module>\n","    from object_detection.metrics import coco_evaluation\n","  File \"/content/DetectWheats/object_detection/metrics/coco_evaluation.py\", line 20, in <module>\n","    from object_detection.metrics import coco_tools\n","  File \"/content/DetectWheats/object_detection/metrics/coco_tools.py\", line 47, in <module>\n","    from pycocotools import coco\n","  File \"/usr/local/lib/python3.6/dist-packages/pycocotools/coco.py\", line 49, in <module>\n","    import matplotlib.pyplot as plt\n","  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\", line 72, in <module>\n","    from matplotlib.backends import pylab_setup\n","  File \"/usr/local/lib/python3.6/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n","    line for line in traceback.format_stack()\n","\n","\n","  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W1004 14:00:13.359964 140330944964480 tf_logging.py:125] Forced number of epochs for all eval validations to be 1.\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W1004 14:00:13.360428 140330944964480 tf_logging.py:125] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fa0dcda2598>) includes params argument, but params are not passed to Estimator.\n","W1004 14:00:13.361272 140330944964480 tf_logging.py:125] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fa0dcda2598>) includes params argument, but params are not passed to Estimator.\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1004 14:00:13.412841 140330944964480 tf_logging.py:125] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/DetectWheats/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","W1004 14:00:14.438070 140330944964480 tf_logging.py:125] From /content/DetectWheats/object_detection/builders/dataset_builder.py:148: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","WARNING:tensorflow:From /content/DetectWheats/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","W1004 14:00:18.890733 140330944964480 tf_logging.py:125] From /content/DetectWheats/object_detection/predictors/heads/box_head.py:93: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /content/DetectWheats/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2108: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W1004 14:00:18.961409 140330944964480 tf_logging.py:125] From /content/DetectWheats/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2108: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/DetectWheats/object_detection/core/losses.py:340: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","W1004 14:00:20.867532 140330944964480 tf_logging.py:125] From /content/DetectWheats/object_detection/core/losses.py:340: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","2018-10-04 14:00:31.458452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2018-10-04 14:00:31.458905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","totalMemory: 11.17GiB freeMemory: 11.10GiB\n","2018-10-04 14:00:31.458943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n","2018-10-04 14:00:31.840563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2018-10-04 14:00:31.840621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n","2018-10-04 14:00:31.840644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n","2018-10-04 14:00:31.840913: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2018-10-04 14:00:31.840974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"],"name":"stdout"}]},{"metadata":{"id":"dRUS35JaSIs7","colab_type":"code","colab":{}},"cell_type":"code","source":["model_step_number = 10000"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h_NgjLYJBEqM","colab_type":"code","colab":{}},"cell_type":"code","source":["!cd DetectWheats && python object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path=$MODEL_DIR/pipeline.config \\\n","    --trained_checkpoint_prefix=$MODEL_DIR/model.ckpt-$model_step_number \\\n","    --output_directory=$MODEL_DIR_out-$model_step_number/out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I1tbTwQ0-Hb5","colab_type":"code","colab":{}},"cell_type":"code","source":["# !cd DetectWheats && python object_detection/inference.py \\\n","# --input_dir=../images/test \\\n","# --output_dir=../images/test/$model_step_number \\\n","# --label_map=annotations/label_map.pbtxt \\\n","# --frozen_graph=faster_rcnn_resnet50_coco_out-$model_step_number/out/frozen_inference_graph.pb \\\n","# --num_output_classes=6"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2cUanIQPSWrE","colab_type":"code","colab":{}},"cell_type":"code","source":["# From tensorflow/models/research/oid\n","# SPLIT=validation  # or test\n","# TF_RECORD_FILES=$(ls -1 ${SPLIT}_tfrecords/* | tr '\\n' ',')\n","\n","# PYTHONPATH=$PYTHONPATH:$(readlink -f ..) \\\n","# python -m object_detection/inference/infer_detections \\\n","#   --input_tfrecord_paths=$TF_RECORD_FILES \\\n","#   --output_tfrecord_path=${SPLIT}_detections.tfrecord-00000-of-00001 \\\n","#   --inference_graph=faster_rcnn_inception_resnet_v2_atrous_oid/frozen_inference_graph.pb \\\n","#   --discard_image_pixels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dYDXStSnTIPq","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from distutils.version import StrictVersion\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","import os,sys,inspect\n","\n","sys.path.insert(0,os.path.join(os.getcwd(),\"DetectWheats\")) \n","sys.path.insert(0,os.path.join(os.getcwd(),\"DetectWheats\",\"object_detection\")) \n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","\n","from object_detection.utils import ops as utils_ops\n","\n","if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n","  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vqad78cWUv6R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a5730a1c-03db-4a49-d0c9-0183a95ca37c","executionInfo":{"status":"ok","timestamp":1538641203721,"user_tz":-180,"elapsed":859,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["# This is needed to display the images.\n","%matplotlib inline\n","print(os.getcwd())"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"metadata":{"id":"7wNdg32OUyQp","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","from utils import label_map_util\n","\n","from utils import visualization_utils as vis_util"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3RJdi9pWU3NJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# What model to download.\n","MODEL_NAME = os.path.join('DetectWheats','faster_rcnn_resnet50_coco_out-10000','out')\n","# MODEL_FILE = MODEL_NAME + '.tar.gz'\n","#DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = os.path.join('DetectWheats','annotations', 'label_map.pbtxt')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xr6WRnOQW6HO","colab_type":"code","colab":{}},"cell_type":"code","source":["detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","  od_graph_def = tf.GraphDef()\n","  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n","    serialized_graph = fid.read()\n","    od_graph_def.ParseFromString(serialized_graph)\n","    tf.import_graph_def(od_graph_def, name='')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s43ZH9BoW8ss","colab_type":"code","colab":{}},"cell_type":"code","source":["category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T3L4KGVhXANV","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_image_into_numpy_array(image):\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-IrKUAdgXDKK","colab_type":"code","colab":{}},"cell_type":"code","source":["# For the sake of simplicity we will use only 2 images:\n","# image1.jpg\n","# image2.jpg\n","# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n","\n","import glob\n","PATH_TO_TEST_IMAGES_DIR = os.path.join('DetectWheats','images', 'test')\n","#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 3) ]\n","TEST_IMAGE_PATHS = glob.glob('DetectWheats/images/test/*.jpg')\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2iyDIimyXFUU","colab_type":"code","colab":{}},"cell_type":"code","source":["def run_inference_for_single_image(image, graph):\n","  with graph.as_default():\n","    with tf.Session() as sess:\n","      # Get handles to input and output tensors\n","      ops = tf.get_default_graph().get_operations()\n","      all_tensor_names = {output.name for op in ops for output in op.outputs}\n","      tensor_dict = {}\n","      for key in [\n","          'num_detections', 'detection_boxes', 'detection_scores',\n","          'detection_classes', 'detection_masks'\n","      ]:\n","        tensor_name = key + ':0'\n","        if tensor_name in all_tensor_names:\n","          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","              tensor_name)\n","      if 'detection_masks' in tensor_dict:\n","        # The following processing is only for single image\n","        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n","        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n","        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n","        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n","        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n","        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","        detection_masks_reframed = tf.cast(\n","            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","        # Follow the convention by adding back the batch dimension\n","        tensor_dict['detection_masks'] = tf.expand_dims(\n","            detection_masks_reframed, 0)\n","      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","      # Run inference\n","      output_dict = sess.run(tensor_dict,\n","                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","      # all outputs are float32 numpy arrays, so convert types as appropriate\n","      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n","      output_dict['detection_classes'] = output_dict[\n","          'detection_classes'][0].astype(np.uint8)\n","      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","      if 'detection_masks' in output_dict:\n","        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","  return output_dict"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lqwesRRMXHMt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":13674,"output_embedded_package_id":"1ojcjRl-6XDDjfNEaF6AVMhRiUi1UVUSJ"},"outputId":"c3fb8191-34ff-47cf-b6e1-181837413284","executionInfo":{"status":"ok","timestamp":1538641425509,"user_tz":-180,"elapsed":211320,"user":{"displayName":"Василий Саенко","photoUrl":"","userId":"04238659998913972664"}}},"cell_type":"code","source":["for image_path in TEST_IMAGE_PATHS:\n","  image = Image.open(image_path)\n","  # the array based representation of the image will be used later in order to prepare the\n","  # result image with boxes and labels on it.\n","  image_np = load_image_into_numpy_array(image)\n","  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","  image_np_expanded = np.expand_dims(image_np, axis=0)\n","  # Actual detection.\n","  output_dict = run_inference_for_single_image(image_np, detection_graph)\n","  # Visualization of the results of a detection.\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks'),\n","      use_normalized_coordinates=True,\n","      line_thickness=8)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(image_np)"],"execution_count":31},{"metadata":{"id":"K3JDO-bIYRRY","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}